# StreamForge CDN Configuration
# This simulates what CloudFront/Akamai do at global scale

events {
    worker_connections 1024;  # Handle 1024 concurrent connections per worker
}

http {
    # Cache storage configuration
    # This creates a 10MB memory zone that can track ~80,000 cached items
    # Actual cached files go to /var/cache/nginx with max size of 10GB
    proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=video_cache:10m max_size=10g
                     inactive=60m use_temp_path=off;

    # Logging format to track cache performance
    log_format cache_status '[$time_local] "$request" $status '
                           'Cache: $upstream_cache_status '
                           'Time: ${request_time}s '
                           'Upstream: ${upstream_response_time}s';

    # Upstream configuration - your origin server
    upstream origin {
        server api:3000;  # Docker service name
        keepalive 32;     # Keep connections alive for performance
    }

    server {
        listen 80;
        access_log /var/log/nginx/access.log cache_status;

        # Health check endpoint for monitoring
        location /health {
            access_log off;
            return 200 "CDN healthy\n";
            add_header Content-Type text/plain;
        }

        # Cache status endpoint - see your hit/miss ratio
        location /cache-status {
            access_log off;
            add_header Content-Type text/plain;
            return 200 "Check nginx logs for cache status\n";
        }

        # API endpoints - no caching for dynamic content
        location ~ ^/api/(upload|jobs|health) {
            proxy_pass http://origin;
            proxy_http_version 1.1;
            proxy_set_header Connection "";

            # Pass original client info to origin
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

            # No caching for API calls
            proxy_cache_bypass 1;
            proxy_no_cache 1;
        }

        # SSE endpoint for real-time updates - special handling
        location ~ ^/api/jobs/[^/]+/progress$ {
            proxy_pass http://origin;
            proxy_http_version 1.1;

            # SSE specific headers
            proxy_set_header Connection "";
            proxy_set_header Cache-Control "no-cache";
            proxy_buffering off;  # Critical for SSE
            proxy_read_timeout 3600s;  # Long timeout for persistent connection

            # Never cache SSE streams
            proxy_cache_bypass 1;
            proxy_no_cache 1;
        }

        # Video streaming endpoint - AGGRESSIVE CACHING
        location ~ ^/api/stream/([^/]+)/([^/]+)$ {
            proxy_pass http://origin;
            proxy_http_version 1.1;
            proxy_set_header Connection "";

            # Enable caching for video content
            proxy_cache video_cache;

            proxy_cache_key $request_uri;

            # Cache successful responses for 1 hour
            proxy_cache_valid 200 206 1h;  # 200 OK and 206 Partial Content
            proxy_cache_valid 404 1m;      # Cache 404s briefly to prevent hammering

            proxy_cache_bypass $arg_nocache;

            # Add headers to show cache status (HIT/MISS/BYPASS)
            add_header X-Cache-Status $upstream_cache_status;
            add_header X-Cache-Key $request_uri;  # Debug header showing cache key

            # Support range requests for video seeking
            proxy_cache_revalidate on;
            proxy_cache_min_uses 1;  # Cache after first request
            proxy_cache_lock on;      # Prevent cache stampede

            # Pass range headers for partial content
            proxy_set_header Range $http_range;
            proxy_set_header If-Range $http_if_range;
        }

        # Static files (future frontend assets)
        location / {
            proxy_pass http://origin;
            proxy_http_version 1.1;
            proxy_set_header Connection "";

            # Cache static assets
            proxy_cache video_cache;
            proxy_cache_key $request_uri;
            proxy_cache_valid 200 10m;

            add_header X-Cache-Status $upstream_cache_status;
        }
    }
}